{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "####**BUILD AND RUN AUGMENTATION PIPELINE**"
      ],
      "metadata": {
        "id": "_Xvt8Awvt6Vr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_IyrKOBct31j"
      },
      "outputs": [],
      "source": [
        "for partition in ['train', 'test', 'val']:\n",
        "  for image in os.listdir(os.path.join('data', partition, 'images')):\n",
        "    img = cv2.imread(os.path.join('data', partition, 'images', image))\n",
        "    coords = [0,0,0.00001,0.00001]\n",
        "    label_path = os.path.join('data', partition, 'labels', f'{image.split(\".\")[0]}.json')\n",
        "    if os.path.exists(label_path):\n",
        "      with open(label_path, 'r') as f:\n",
        "        label = json.load(f)\n",
        "      xs = [p[0] for p in label['shapes'][0]['points']]\n",
        "      ys = [p[1] for p in label['shapes'][0]['points']]\n",
        "      xmin, xmax = min(xs), max(xs)\n",
        "      ymin, ymax = min(ys), max(ys)\n",
        "      coords[0] = xmin\n",
        "      coords[1] = ymin\n",
        "      coords[2] = xmax\n",
        "      coords[3] = ymax\n",
        "      coords = list(np.divide(coords, [640,480,640,480]))\n",
        "\n",
        "    try:\n",
        "      for x in range(60):\n",
        "        augmented = augmentor(image=img, bboxes=[coords], class_labels=['face'])\n",
        "        cv2.imwrite(os.path.join('aug_data', partition, 'images', f'{image.split(\".\")[0]}.{x}.jpg'), augmented['image'])\n",
        "\n",
        "        annotation = {}\n",
        "        annotation['image'] = image\n",
        "\n",
        "        if os.path.exists(label_path):\n",
        "          if len(augmented['bboxes']) == 0:\n",
        "            annotation['bbox'] = [0,0,0,0]\n",
        "            annotation['class'] = 0\n",
        "          else:\n",
        "            annotation['bbox'] = augmented['bboxes'][0]\n",
        "            annotation['class'] = 1\n",
        "        else:\n",
        "          annotation['bbox'] = [0,0,0,0]\n",
        "          annotation['class'] = 0\n",
        "\n",
        "        with open(os.path.join('aug_data', partition, 'labels', f'{image.split(\".\")[0]}.{x}.json'), 'w') as f:\n",
        "          json.dump(annotation, f)\n",
        "    except Exception as e:\n",
        "      print(e)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for folder in ['train', 'test', 'val']:\n",
        "  for file in os.listdir(os.path.join('data', folder, 'images')):\n",
        "    filename = file.split('.')[0]+'.json'\n",
        "    existing_filepath = os.path.join('data', 'labels', filename)\n",
        "    if os.path.exists(existing_filepath):\n",
        "      new_filepath = os.path.join('data', folder, 'labels', filename)\n",
        "      os.replace(existing_filepath, new_filepath)"
      ],
      "metadata": {
        "id": "RWNpQf5vvGaA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = tf.data.Dataset.list_files('aug_data/train/images/*.jpg', shuffle=False)\n",
        "train_images = train_images.map(load_image)\n",
        "train_images = train_images.map(lambda x: tf.image.resize(x, (120,120)))\n",
        "train_images = train_images.map(lambda x: x/255)"
      ],
      "metadata": {
        "id": "JURveVqDvcrM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_images = tf.data.Dataset.list_files('aug_data/test/images/*.jpg', shuffle=False)\n",
        "test_images = test_images.map(load_image)\n",
        "test_images = test_images.map(lambda x: tf.image.resize(x, (120,120)))\n",
        "test_images = test_images.map(lambda x: x/255)"
      ],
      "metadata": {
        "id": "Oo5qnozZvdBn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_images = tf.data.Dataset.list_files('aug_data/val/images/*.jpg', shuffle=False)\n",
        "val_images = val_images.map(load_image)\n",
        "val_images = val_images.map(lambda x: tf.image.resize(x, (120,120)))\n",
        "val_images = val_images.map(lambda x: x/255)"
      ],
      "metadata": {
        "id": "ETIWd6u_vfIX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}